{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compter dans le fichier Feuille Charline les indices dont on possède un fichier G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chemins des dossiers (je travaille avec les données en local et je ne push que le jupyter notebook)\n",
    "\n",
    "dossier_facile = r\"\"\n",
    "dossier_difficile = r\"\"\n",
    "fichier_principal = r\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'85', '80', '119', '58', '40', '146', '47', '108', '53', '65', '121', '110', '79', '52', '88', '162', '46', '60', '66', '99', '140', '70', '125', '50', '49', '69', '135', '158', '131', '45', '116', '84', '71', '86', '68', '160', '61', '157', '56', '148', '141', '64', '87', '44', '98', '89', '55', '97', '139', '115', '145', '147', '82', '78', '62', '144'}\n",
      "{'104', '132', '156', '161', '54', '78'}\n"
     ]
    }
   ],
   "source": [
    "# Récupérer tous les indice des fichiers G dans les deux dossiers et voir combien sont présents dans les deux\n",
    "\n",
    "def extraire_indices(dossier):\n",
    "    indices = set()\n",
    "    for fichier in os.listdir(dossier):\n",
    "        match = re.search(r'\\d+', fichier)  \n",
    "        if match:\n",
    "            indices.add(match.group())  \n",
    "    return indices\n",
    "\n",
    "indices_faciles = extraire_indices(dossier_facile)\n",
    "indices_difficiles = extraire_indices(dossier_difficile)\n",
    "\n",
    "print(indices_faciles)\n",
    "print(indices_difficiles)\n",
    "\n",
    "indices_existants = indices_faciles.union(indices_difficiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['104', '108', '110', '115', '116', '119', '121', '125', '131', '132', '135', '139', '140', '141', '144', '145', '146', '147', '148', '156', '157', '158', '160', '161', '162', '45', '46', '47', '49', '50', '52', '53', '54', '55', '56', '58', '61', '62', '64', '65', '66', '68', '69', '70', '71', '78', '79', '80', '82', '84', '85', '86', '87', '89', '97', '98']\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "# Charger le fichier principal et récupérer les indices\n",
    "\n",
    "df = pd.read_csv(fichier_principal, sep=\";\", usecols=[0], encoding=\"latin1\") \n",
    "indices_principal = set(df[\"ID\"].dropna().astype(str))\n",
    "\n",
    "indices_match = sorted(indices_principal.intersection(indices_existants))\n",
    "\n",
    "print(indices_match)\n",
    "print(len(indices_match))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il n'y a donc que 56 fichiers G dont on connaît l'issue au moment de feuille Charline. Probablement pas assez pour du supervisé genre Random Forest ou XGBOOST mais on peut envisager d'autres méthodes supervisées qui nécéssitent moins de données"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
